<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to PlackettLuce • PlackettLuce</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">PlackettLuce</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Overview.html">Introduction to PlackettLuce</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/hturner/PlackettLuce">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Introduction to PlackettLuce</h1>
                        <h4 class="author">Heather Turner</h4>
            <address class="author_afil">
      Department of Statistics, University of Warwick, UK<br><h4 class="author">Jacob van Etten</h4>
            <address class="author_afil">
      Bioversity International, Costa Rica<br><h4 class="author">David Firth</h4>
            <address class="author_afil">
      Department of Statistics, University of Warwick, UK<br><h4 class="author">Ioannis Kosmidis</h4>
            <address class="author_afil">
      Department of Statistical Science, UCL, UK<br>
</address>
</address>
</address>
</address>
</div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>The <strong>PlackettLuce</strong> package implements a generalization of the model jointly attributed to <span class="citation">Plackett (<a href="#ref-Plackett1975">1975</a>)</span> and <span class="citation">R. Luce (<a href="#ref-Luce1959">1959</a>)</span> for modelling rankings data. The generalization accomodates both ties (of any order) and partial rankings (rankings of only some items). By default, the implementation adds a set pseudo-rankings with a hypothetical item, ensuring that the network of wins and losses is always strongly connected, i.e. all items are connected to every other item by both a path of wins and a path of losses. This means that the worth of each item is always estimable with finite standard error. It also has a shrinkage effect, regularizing the estimated parameters. In addition to standard methods for model summary, <strong>PlackettLuce</strong> provides a method to estimate quasi-standard errors for the item parameters, so that comparison intervals can be derived even when a reference item is set. Finally the package provides a method for model-based partitioning, enabling the identification of subgroups of subjects that rank items differently.</p>
    </div>
    
<div class="contents">
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>Rankings data, in which each observation is an ordering of a set of items, arises in a range of applications, for example sports tournaments and consumer studies. A classic model for such data is the Plackett-Luce model. This model depends on Luce’s axiom of choice <span class="citation">(R. D. Luce <a href="#ref-Luce1977">1977</a>)</span> which states that the odds of choosing item 1 over item 2 do not depend on the set of items from which the choice is made. Suppose we have a set of items</p>
<p><span class="math display">\[S_j = {i_1, i_2, \ldots, i_J}.\]</span></p>
<p>Then under Luce’s axiom, the probability of selecting item <span class="math inline">\(j\)</span> is given by</p>
<p><span class="math display">\[P(i_j | S_j) = \frac{\alpha_{i_j}}{\sum_{c \in S_j} \alpha_c}\]</span></p>
<p>where <span class="math inline">\(\alpha_j\)</span> represents the <strong>worth</strong> of item <span class="math inline">\(j\)</span>. Viewing a ranking of <span class="math inline">\(K\)</span> items as a sequence of choices—first choosing the top-ranked item from all items, then choosing the second-ranked item from the remaining items and so on—it follows that the probability of a ranking <span class="math inline">\({i_1 &gt; \ldots &gt; i_K}\)</span> is given by</p>
<p><span class="math display">\[\prod_{j=1}^K \frac{\alpha_{i_j}}{\sum_{c \in S_j} \alpha_c}\]</span></p>
<p>The above model is also derived in <span class="citation">Plackett (<a href="#ref-Plackett1975">1975</a>)</span>, hence the name Plackett-Luce model.</p>
<p>The <strong>PlackettLuce</strong> package implements a novel extension of the Plackett-Luce model that accommodates tied rankings, which may be applied to either full or partial rankings. Pseudo-rankings are utilised to obtain estimates in cases where the maximum likelihood estimates do not exist, or do not have finite standard errors. Methods are provided to obtain different parameterisations with corresponding standard errors or quasi-standard errors (that are independent of the reference item). There is also a method to work with the <strong>psychotree</strong> package to fit Plackett-Luce trees.</p>
<div id="comparison-with-other-packages" class="section level2">
<h2 class="hasAnchor">
<a href="#comparison-with-other-packages" class="anchor"></a>Comparison with other packages</h2>
<p>Even though the Plackett-Luce model is a well-established method for analysing rankings, the software available to fit the model is limited. By considering each choice in the ranking as a multinomial observation, with one item observed out of a possible set, the “Poisson trick” can be applied to express the model as a log-linear model, where the response is the count (one or zero) of each possible outcome within each choice. In theory, the model can then be fitted using standard software for generalized linear models. However there are a number of difficulties with this. Firstly, dummy variables must be set up to represent the presense or absense of each item in each choice and a factor created to identify each choice, which is a non-standard task. Secondly the factor identifying each choice will have many levels: greater than the number of rankings for rankings of more than two objects. Thus there are many parameters to estimate and a standard function such as <code>glm</code> will be slow to fit the model, or may even fail as the corresponding model matrix will be too large to fit in memory. This issue can be circumvented by using the <code>gnm</code> function from <strong>gnm</strong>, which provides an <code>eliminate</code> argument to efficiently estimate the effects of such a factor. Even then, the model-fitting may be relatively slow, given the expansion in the number of observations converting from rankings to counts. For example, the ranking {item 3 &gt; item 1 &gt; item 2} expands to two choices with five counts all together:</p>
<pre><code>##      choice item 1 item 2 item 3 count
## [1,]      1      1      0      0     0
## [2,]      1      0      1      0     0
## [3,]      1      0      0      1     1
## [4,]      2      1      0      0     1
## [5,]      2      0      1      0     0</code></pre>
<p>It is possible to aggregate observations of the same choice from the same set of alternatives, but the number of combinations increases quickly with the number of items.</p>
<p>Given the issues with applying general methods, custom algorithms and software have been developed. One approach is use Hunter’s <span class="citation">(<a href="#ref-Hunter2004">2004</a>)</span> minorization-maximization (MM) algorithm to maximize the likelihood, which is equivalent to an iterative scaling algorithm; this algorithm is used by the <strong>StatRank</strong> package. Alternatively the likelihood of the observed data under the PlackettLuce model can be maximised directly using a generic optimisation method such the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm, as used by both the <strong>pmr</strong> and <strong>hyper2</strong> packages. Finally Bayesian methods can be used to either maximize the posterior distribution via an Expectation Maximization (EM) algorithm or to simulate the posterior distribution using Markov-chain Monte-Carlo (MCMC) techniques, both of which are provided by <strong>PLMIX</strong>. <strong>PlackettLuce</strong> offers both iterative scaling and generic optimization using either BFGS or a limited memory variant (L-BFGS) via the <strong>lbfgs</strong> package.</p>
<p>Even some of these specialized implementations can scale poorly with the number of items and/or the number of rankings as shown by the example timings in Table @ref(tab:timings-kable). Specifically <code><a href="http://www.rdocumentation.org/packages/pmr/topics/pl">pmr::pl</a></code> becomes impractical to use with a moderate number of items (~10), while the functions from <strong>hyper2</strong> and <strong>StatRank</strong> take much longer to run with a large number (1000s) of unique rankings. <strong>PlackettLuce</strong> copes well with these moderately-sized data sets, though is not quite as fast as <strong>PLMIX</strong> when both the number of items and the number of unique rankings is large.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
Features of example data sets from PrefLib <span class="citation">(Mattei and Walsh <a href="#ref-Mattei2013">2013</a>)</span>
</caption>
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Rankings
</th>
<th style="text-align:right;">
Unique rankings
</th>
<th style="text-align:right;">
Items
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
Netflix
</td>
<td style="text-align:right;">
1256
</td>
<td style="text-align:right;">
24
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:left;">
T-shirt
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
11
</td>
</tr>
<tr>
<td style="text-align:left;">
Sushi
</td>
<td style="text-align:right;">
5000
</td>
<td style="text-align:right;">
4926
</td>
<td style="text-align:right;">
10
</td>
</tr>
</tbody>
</table>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
Timings for fitting the Plackett-Luce model to data sets summarised in Table @ref(tab:data-features) using different packages. See Appendix for details and code.
</caption>
<thead>
<tr>
<th style="border-bottom:hidden">
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="5">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Time elapsed (s)
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
PlackettLuce
</th>
<th style="text-align:right;">
hyper2
</th>
<th style="text-align:right;">
PLMIX
</th>
<th style="text-align:right;">
pmr
</th>
<th style="text-align:right;">
StatRank
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Netflix
</td>
<td style="text-align:right;">
0.128
</td>
<td style="text-align:right;">
0.114
</td>
<td style="text-align:right;">
0.161
</td>
<td style="text-align:right;">
0.452
</td>
<td style="text-align:right;">
0.870
</td>
</tr>
<tr>
<td style="text-align:left;">
T-shirt
</td>
<td style="text-align:right;">
0.316
</td>
<td style="text-align:right;">
0.161
</td>
<td style="text-align:right;">
0.071
</td>
<td style="text-align:right;">
a
</td>
<td style="text-align:right;">
7.209
</td>
</tr>
<tr>
<td style="text-align:left;">
Sushi
</td>
<td style="text-align:right;">
1.584
</td>
<td style="text-align:right;">
81.952
</td>
<td style="text-align:right;">
0.165
</td>
<td style="text-align:right;">
b
</td>
<td style="text-align:right;">
17.518
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border:0;" colspan="100%">
<sup>a</sup> Failed to allocate vector of size: 2125.7 Gb
</td>
</tr>
<tr>
<td style="padding: 0; border:0;" colspan="100%">
<sup>b</sup> Failed to allocate vector of size: 74.5 Gb
</td>
</tr>
</tfoot>
</table>
<p>When the number of items is more than ten, it is more common to observe partial rankings than complete rankings. Partial rankings can be of two types: <em>sub-rankings</em>, where only a subset of items are ranked each time, and <em>incomplete rankings</em>, where the top <span class="math inline">\(n\)</span> items are selected and the remaining items are unranked, but implictly ranked lower than the top <span class="math inline">\(n\)</span>. Sub-rankings are accommodated by the standard Plackett-Luce model, while incomplete rankings require an extension of the Plackett-Luce model. <strong>PlackettLuce</strong> handles sub-rankings only, while <strong>PLMIX</strong> handles incomplete rankings only and <strong>hyper2</strong> can handle both types. (<strong>StatRank</strong> supports partial rankings, but it is not clear in which form). Table @ref(tab:nascar) demonstrates using the NASCAR data from <span class="citation">Hunter (<a href="#ref-Hunter2004">2004</a>)</span> that <strong>PlackettLuce</strong> is more efficient than <strong>hyper2</strong> for modelling subrankings of a relatively large number of items.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
Timings for fitting the Plackett-Luce model to the NASCAR data from <span class="citation">Hunter (<a href="#ref-Hunter2004">2004</a>)</span>. All rankings are unique.
</caption>
<thead>
<tr>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Features of NASCAR data
</div>
</th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">
Time elapsed (s)
</div>
</th>
</tr>
<tr>
<th style="text-align:right;">
Rankings
</th>
<th style="text-align:right;">
Items
</th>
<th style="text-align:right;">
Items per ranking
</th>
<th style="text-align:right;">
PlackettLuce
</th>
<th style="text-align:right;">
hyper2
</th>
</tr>
</thead>
<tbody><tr>
<td style="text-align:right;">
36
</td>
<td style="text-align:right;">
83
</td>
<td style="text-align:right;">
42-43
</td>
<td style="text-align:right;">
0.232
</td>
<td style="text-align:right;">
74.384
</td>
</tr></tbody>
</table>
<p><strong>PlackettLuce</strong> is the only package out of those based on maximum likelihood estimation with the functionality to compute standard errors for the item parameters and thereby the facility to conduct inference on these parameters. Using <strong>PLMIX</strong>, inference may be based on the posterior distribution. In some cases, when the network of wins and losses is disconnected or weakly connected, the maximum likelihood estimate does not exist, or has infinite standard error; such issues are handled in <strong>PlackettLuce</strong> by utilising pseudo-rankings. This is similar to incorporating prior information as in the Bayesian approach.</p>
<p><strong>PlackettLuce</strong> is the only package that can accommodated tied rankings, this is achieved through a novel extension of the Plackett-Luce model. On the other hand <strong>hyper2</strong> is currently the only package that can handle rankings of combinations of items, for example team rankings in sports. <strong>PLMIX</strong> offers the facility to model heterogenous populations of subjects that have different sets of worth parameters via mixture models. This is similar in spirit to the model-based partitioning offered by <strong>PlackettLuce</strong>, except here the sub-populations are defined by binary splits on subject attributes. A summary of the package features is given in Table @ref(tab:package-summary).</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
Features of packages for fitting the Plackett-Luce model.
</caption>
<thead><tr>
<th style="text-align:left;">
Feature
</th>
<th style="text-align:left;">
PlackettLuce
</th>
<th style="text-align:left;">
hyper2
</th>
<th style="text-align:left;">
pmr
</th>
<th style="text-align:left;">
StatRank
</th>
<th style="text-align:left;">
PLMIX
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
Inference
</td>
<td style="text-align:left;">
Frequentist
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Bayesian
</td>
</tr>
<tr>
<td style="text-align:left;">
Disconnected networks
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
</tr>
<tr>
<td style="text-align:left;">
Ties
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
</tr>
<tr>
<td style="text-align:left;">
Teams
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
</tr>
<tr>
<td style="text-align:left;">
Heterogenous case
</td>
<td style="text-align:left;">
Trees
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Mixtures
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="methods" class="section level1">
<h1 class="hasAnchor">
<a href="#methods" class="anchor"></a>Methods</h1>
<div id="extended-plackett-luce-model" class="section level2">
<h2 class="hasAnchor">
<a href="#extended-plackett-luce-model" class="anchor"></a>Extended Plackett-Luce model</h2>
<p>The <strong>PlackettLuce</strong> package permits rankings of the form</p>
<p><span class="math display">\[R = \{C_1, C_2, \ldots, C_J\}\]</span></p>
<p>where the items in set <span class="math inline">\(C_1\)</span> are ranked higher than (better than) the items in <span class="math inline">\(C_2\)</span>, and so on. If there are multiple objects in set <span class="math inline">\(C_j\)</span> these items are tied in the ranking. For a set <span class="math inline">\(S\)</span>, let</p>
<p><span class="math display">\[f(S) = \delta_{|S|} \left(\prod_{i \in S} \alpha_i \right)^\frac{1}{|S|}\]</span></p>
<p>where <span class="math inline">\(|S|\)</span> is the cardinality of the set, <span class="math inline">\(\delta_n\)</span> is a parameter representing the prevalence of ties of order <span class="math inline">\(n\)</span>, and <span class="math inline">\(\alpha_i\)</span> is a parameter representing the worth of item <span class="math inline">\(i\)</span>. Then under an extension of the Plackett-Luce model allowing ties up to order <span class="math inline">\(D\)</span>, the probability of the ranking <span class="math inline">\(R\)</span> is given by</p>
<span class="math display">\[\begin{equation}
\prod_{j = 1}^J \frac{f(C_j)}{
\sum_{k = 1}^{\text{min}(D_j, D)} \sum_{S \in {A_j \choose k}} f(S)}
(\#eq:PL)
\end{equation}\]</span>
<p>where <span class="math inline">\(D_j\)</span> is the cardinality of <span class="math inline">\(C_j\)</span>, <span class="math inline">\(A_j\)</span> is the set of alternatives from which <span class="math inline">\(C_j\)</span> is chosen, and <span class="math inline">\(A_j \choose k\)</span> is all the possible choices of <span class="math inline">\(k\)</span> items from <span class="math inline">\(A_j\)</span>. The value of <span class="math inline">\(D\)</span> can be set to the maximum number of tied items observed in the data, so that <span class="math inline">\(\delta_n = 0\)</span> for <span class="math inline">\(n &gt; D\)</span>.</p>
<p>When the worth parameters are constrained to sum to one, they represent the probability that the corresponding item comes first in a ranking of all items, given that first place is not tied.</p>
<div id="pudding-example-with-ties" class="section level3">
<h3 class="hasAnchor">
<a href="#pudding-example-with-ties" class="anchor"></a>Pudding example (with ties)</h3>
<p>When each ranking contains only two items, then the model in Equation @ref(eq:PL) reduces to extended Bradley-Terry model proposed by <span class="citation">Davidson (<a href="#ref-Davidson1970">1970</a>)</span> for paired comparisons with ties. The <code>pudding</code> data set, available in <strong>PlackettLuce</strong> provides the data from Example 2 of that paper, in which respondents were asked to test two brands of chocolate pudding from a total of six brands. For each comparison of brands <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, the data set gives the frequencies that brand <span class="math inline">\(i\)</span> was preferred (<span class="math inline">\(w_{ij}\)</span>), that brand <span class="math inline">\(j\)</span> was preferred (<span class="math inline">\(w_{ji}\)</span> and that the brands were tied (<span class="math inline">\(t_{ij}\)</span>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PlackettLuce)
<span class="kw">head</span>(pudding)</code></pre></div>
<pre><code>##   i j r_ij w_ij w_ji t_ij
## 1 1 2   57   19   22   16
## 2 1 3   47   16   19   12
## 3 2 3   48   19   19   10
## 4 1 4   54   18   23   13
## 5 2 4   51   23   19    9
## 6 3 4   54   19   20   15</code></pre>
<p>First we create a matrix representing each unique ranking, as required by <code>PlackettLuce</code>, the model-fitting function in <strong>PlackettLuce</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nr &lt;-<span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="kw">nrow</span>(pudding)
R &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> nr, <span class="dt">ncol =</span> <span class="dv">6</span>,
            <span class="dt">dimnames =</span> <span class="kw">list</span>(<span class="ot">NULL</span>, <span class="kw">seq_len</span>(<span class="dv">6</span>)))
i &lt;-<span class="st"> </span><span class="kw">rep</span>(pudding<span class="op">$</span>i, <span class="dv">3</span>)
j &lt;-<span class="st"> </span><span class="kw">rep</span>(pudding<span class="op">$</span>j, <span class="dv">3</span>)
R[<span class="kw">cbind</span>(<span class="kw">seq_len</span>(nr), i)] &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">each =</span> <span class="kw">nrow</span>(pudding))
R[<span class="kw">cbind</span>(<span class="kw">seq_len</span>(nr), j)] &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">each =</span> <span class="kw">nrow</span>(pudding))
<span class="kw">head</span>(R, <span class="dv">3</span>)</code></pre></div>
<pre><code>##      1 2 3 4 5 6
## [1,] 1 2 0 0 0 0
## [2,] 1 0 2 0 0 0
## [3,] 0 1 2 0 0 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tail</span>(R, <span class="dv">3</span>)</code></pre></div>
<pre><code>##       1 2 3 4 5 6
## [43,] 0 0 1 0 0 1
## [44,] 0 0 0 1 0 1
## [45,] 0 0 0 0 1 1</code></pre>
<p>The matrix <code>R</code> represents first the wins of <span class="math inline">\(i\)</span> over <span class="math inline">\(j\)</span>, then the wins of <span class="math inline">\(j\)</span> over <span class="math inline">\(i\)</span> and finally the ties, so is three times as long as the original data. Each column represents a brand. In each row <code>0</code> represents an unranked brand (not in the comparison), <code>1</code> represents the brand(s) ranked in first place and <code>2</code> represents the brand in second place, if applicable.</p>
<p>This matrix can used to specify the rankings in the call to <code>PlackettLuce</code>, however there are some advantages to creating a formal  object, which <code>PlackettLuce</code> create internally if necessary:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rankings.html">as.rankings</a></span>(R)
<span class="kw">head</span>(R)</code></pre></div>
<pre><code>## [1] "1 &gt; 2" "1 &gt; 3" "2 &gt; 3" "1 &gt; 4" "2 &gt; 4" "3 &gt; 4"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tail</span>(R)</code></pre></div>
<pre><code>## [1] "4 = 5" "1 = 6" "2 = 6" "3 = 6" "4 = 6" "5 = 6"</code></pre>
<p>The <code>as.rankings</code> method checks that the rankings are specified as dense rankings, i.e. consecutive integers with no rank skipped for tied items, recoding as necessary; drops rankings with less than two items since these are uninformative, and adds column names if necessary. As can be seen above, the print method displays the rankings in a more readable form.</p>
<p>To specify the full set of rankings, we need the frequency of each ranking, which will be specified to the model0fitting function as a weight vector:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">w &lt;-<span class="st"> </span><span class="kw">unlist</span>(pudding[<span class="kw">c</span>(<span class="st">"w_ij"</span>, <span class="st">"w_ji"</span>, <span class="st">"t_ij"</span>)])</code></pre></div>
<p>Now we can fit the model with <code>PlackettLuce</code>, passing the rankings matrix and the weight vector as arguments. Setting <code>npseudo = 0</code> means that standard maximum likelihood estimation is performed and <code>maxit = 7</code> limits the number of iterations to obtain the same worth parameters as <span class="citation">Davidson (<a href="#ref-Davidson1970">1970</a>)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod &lt;-<span class="st"> </span><span class="kw"><a href="../reference/PlackettLuce.html">PlackettLuce</a></span>(R, <span class="dt">weights =</span> w, <span class="dt">npseudo =</span> <span class="dv">0</span>, <span class="dt">maxit =</span> <span class="dv">7</span>)</code></pre></div>
<pre><code>## Warning in PlackettLuce(R, weights = w, npseudo = 0, maxit = 7): Iterations
## have not converged.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(mod, <span class="dt">log =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>##         1         2         3         4         5         6      tie2 
## 0.1389750 0.1729960 0.1618192 0.1653960 0.1587648 0.2020490 0.7466951</code></pre>
<p>Note here we specify <code>log = FALSE</code> to give the parameterization as in Equation @ref(eq:PL). In the next section we discuss why it is more appropriate to use the log scale for inference.</p>
</div>
</div>
<div id="inference" class="section level2">
<h2 class="hasAnchor">
<a href="#inference" class="anchor"></a>Inference</h2>
<p>A standard way to report model parameters is to report them along with their corresponding standard error. This is an indication of the estimate’s precision, however implicitly this invites comparison with zero. Such comparison is made explicit in many summary methods for models in R, with the addition of partial t or Z tests testing the null hypothesis that the parameter is equal to zero, given the other parameters in the model. However this hypothesis is generally not of interest for the worth parameters in a Plackett-Luce model: we expect most items to have <em>some</em> worth, the question is whether the items differ in their worth. In addition, a Z test based on asymptotic normality of the maximum likelihood estimate will not be appropriate for worth parameters near zero or one, since it does not take account of the fact that the parameters cannot be outside of these limits.</p>
<p>On the log scale however, there are no bounds on the parameters and we can set a reference level to provide meaningful comparisons. By default, the summary method for  objects sets the first item as the reference:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## Call: PlackettLuce(rankings = R, npseudo = 0, weights = w, maxit = 7)
## 
## Coefficients:
##      Estimate Std. Error z value Pr(&gt;|z|)    
## 1      0.0000         NA      NA       NA    
## 2      0.2190     0.1872   1.170 0.242120    
## 3      0.1522     0.1935   0.786 0.431598    
## 4      0.1741     0.1882   0.925 0.355065    
## 5      0.1331     0.1927   0.691 0.489634    
## 6      0.3742     0.1924   1.945 0.051755 .  
## tie2  -0.2921     0.0825  -3.541 0.000399 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual deviance:  1619.4  on  1484  degrees of freedom
## AIC:  1631.4 
## Number of iterations: 8</code></pre>
<p>None of the Z tests for the item parameters is significant, which is consistent with test for equal preferences presented in <span class="citation">Davidson (<a href="#ref-Davidson1970">1970</a>)</span>. Note the tie parameter is alo shown on the log scale here, but since it is an integral part of the model it is not a parameter of interest for inference, so the scale is not relevant.</p>
<p>The reference level for the item parameters can be changed via the <code>ref</code> argument, for example setting to <code>NULL</code> sets the mean worth as the reference:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(mod, <span class="dt">ref =</span> <span class="ot">NULL</span>)</code></pre></div>
<pre><code>## Call: PlackettLuce(rankings = R, npseudo = 0, weights = w, maxit = 7)
## 
## Coefficients:
##       Estimate Std. Error z value Pr(&gt;|z|)    
## 1    -0.175426   0.121939  -1.439 0.150253    
## 2     0.043548   0.121813   0.358 0.720715    
## 3    -0.023240   0.126818  -0.183 0.854599    
## 4    -0.001377   0.121998  -0.011 0.990994    
## 5    -0.042296   0.127049  -0.333 0.739203    
## 6     0.198790   0.126580   1.570 0.116305    
## tie2 -0.292098   0.082500  -3.541 0.000399 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual deviance:  1619.4  on  1484  degrees of freedom
## AIC:  1631.4 
## Number of iterations: 8</code></pre>
<p>As can be seen from the output above, the standard error of the item parameters changes with the reference level. Therefore in cases where there is not a natural reference (e.g. own brand versus competitor’s brands), the inference can depend on an arbitrary choice. This problem can be handled through the use of <em>quasi standard errors</em> that remain constant for a given item regardless of the reference. In addition quasi standard errors are defined for the reference item, so even in cases where there is a natural reference, the uncertainty around the worth of that item can still be represented.</p>
<p>Quasi standard errors for the item parameters are implemented via a method for the <code>qvcalc</code> function from the <strong>qvalc</strong> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qv &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/qvcalc/topics/qvcalc">qvcalc</a></span>(mod)
qv</code></pre></div>
<pre><code>##    estimate        SE   quasiSE   quasiVar
## 1 0.0000000 0.0000000 0.1328834 0.01765799
## 2 0.2189744 0.1872050 0.1327324 0.01761790
## 3 0.1521861 0.1935076 0.1395693 0.01947959
## 4 0.1740489 0.1881999 0.1330195 0.01769418
## 5 0.1331303 0.1926938 0.1399200 0.01957760
## 6 0.3742162 0.1923830 0.1391874 0.01937314</code></pre>
<p>Again by default, the first item is taken as the reference, but this may be changed via a <code>ref</code> argument. The plot method for the returned object visualizes the item parameters (log-worth parameters) along with comparison intervals - item parameters for which the comparison intervals do not cross are significantly different:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(qv, <span class="dt">xlab =</span> <span class="st">"Brand of pudding"</span>, <span class="dt">ylab =</span> <span class="st">"Worth (log)"</span>, <span class="dt">main =</span> <span class="ot">NULL</span>)</code></pre></div>
<div class="figure">
<img src="Overview_files/figure-html/pudding-qv-1.png" alt="Worth of brands of chocolate pudding. Intervals based on quasi-standard errors." width="672"><p class="caption">
Worth of brands of chocolate pudding. Intervals based on quasi-standard errors.
</p>
</div>
</div>
<div id="disconnected-networks" class="section level2">
<h2 class="hasAnchor">
<a href="#disconnected-networks" class="anchor"></a>Disconnected networks</h2>
<p>The wins and losses between items can be represented as a directed network. For example, consider the following set of paried comparisons:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>,
              <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>,
              <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>,
              <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>,
              <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>), <span class="dt">byrow =</span> <span class="ot">TRUE</span>, <span class="dt">ncol =</span> <span class="dv">4</span>,
            <span class="dt">dimnames =</span> <span class="kw">list</span>(<span class="ot">NULL</span>, LETTERS[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>]))
R &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rankings.html">as.rankings</a></span>(R)</code></pre></div>
<p>The <code>adjacency</code> function from <strong>PlacketLuce</strong> can be used to convert these to an adjace`ncy matrix where element <span class="math inline">\((i, j)\)</span> is the number of times item <span class="math inline">\(i\)</span> is ranked higher than item <span class="math inline">\(j\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw"><a href="../reference/adjacency.html">adjacency</a></span>(R)
A</code></pre></div>
<pre><code>##   A B C D
## A 0 1 0 1
## B 1 0 1 0
## C 1 0 0 0
## D 0 0 0 0
## attr(,"class")
## [1] "adjacency" "matrix"</code></pre>
<p>Using functions from <strong>igraph</strong> we can visualise the corresponding network:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(igraph)
net &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/igraph/topics/graph_from_adjacency_matrix">graph_from_adjacency_matrix</a></span>(A)
<span class="kw">plot</span>(net, <span class="dt">edge.arrow.size =</span> <span class="fl">0.5</span>, <span class="dt">vertex.size =</span> <span class="dv">30</span>)</code></pre></div>
<div class="figure">
<img src="Overview_files/figure-html/always-loses-1.png" alt="Network representation of toy rankings." width="672"><p class="caption">
Network representation of toy rankings.
</p>
</div>
<p>For the worth parameters to have finite maximum likelihood estimates (MLEs) and standard errors, the network must be strongly connected, i.e. there must be a path of wins and a path of losses between each pair of items. In the example above, A, B and C are strongly connected. For example, C directly loses against B and although C never directly beats B, it does beat A and A in turn beats B, so C indirectly beats B. Similar paths of wins and losses can be found for all pairs of A, B and C. On the other hand D is only observed to lose, therefore the MLE of the worth would be zero, with infinite standard error.</p>
<p>If one item always wins, the MLE of the worth would be one with infinite standard error. Or if there are clusters of items that are strongly connected with each other, but disconnected or connected only by wins or only by loses (weakly connected) to other clusters, then the maximum likelihood estimates are undefined, because there is no information on the relative worth of the clusters or one cluster is infinitely worse than the other.</p>
<p>The connectivity of the network can be checked with the <code>connectivity</code> function from <strong>PlackettLuce</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/connectivity.html">connectivity</a></span>(A)</code></pre></div>
<pre><code>## Network of items is not strongly connected</code></pre>
<pre><code>## $membership
## A B C D 
## 1 1 1 2 
## 
## $csize
## [1] 3 1
## 
## $no
## [1] 2</code></pre>
<p>If the netwrok is not strongly connected, information on the clusters within the network is returned. In this case a model could be estimated excluding item D:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R2 &lt;-<span class="st"> </span>R[, <span class="op">-</span><span class="dv">4</span>]</code></pre></div>
<pre><code>## Removed rankings with less than 2 items</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R2</code></pre></div>
<pre><code>## [1] "A &gt; B" "C &gt; A" "B &gt; A" "B &gt; C"</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod &lt;-<span class="st"> </span><span class="kw"><a href="../reference/PlackettLuce.html">PlackettLuce</a></span>(R2, <span class="dt">npseudo =</span> <span class="dv">0</span>)
<span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## Call: PlackettLuce(rankings = R2, npseudo = 0)
## 
## Coefficients:
##   Estimate Std. Error z value Pr(&gt;|z|)
## A   0.0000         NA      NA       NA
## B   0.8392     1.3596   0.617    0.537
## C   0.4196     1.5973   0.263    0.793
## 
## Residual deviance:  5.1356  on  2  degrees of freedom
## AIC:  9.1356 
## Number of iterations: 9</code></pre>
<p>Note that since <code>R</code> is a rankings object, the rankings are automatically updated when items are dropped, so in this case the paired comparison with item D is dropped.</p>
<p>By default however <strong>PlackettLuce</strong> provides a way to handle disconnected/weakly connected networks, through the addition of pseudo-rankings. This works by adding a win and a loss between each item and a hypothetical or ghost item with fixed worth. This makes the network strongly connected so all the worth parameters are estimable. It also has an interpretation as a Bayesian prior, in particular a non-informative prior where all items have equal worth.</p>
<p>The <code>npseudo</code> argument defines the number of wins and loses with the ghost item that are added for each real item. Setting <code>npseudo = 0</code> doesn’t add any pseudo-rankings, so <code>PlackettLuce</code> will return the standard MLE, if the network is strongly connected, and throw an error otherwise. The larger <code>npseudo</code> is, the stronger the influence of the prior, so by default <code>npseudo</code> is set to 0.5, so each pseudo-ranking is weighted by 0.5. This is enough to connect the network, but is a weak prior. In this toy example, the item parameters changes quite considerably:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/PlackettLuce.html">PlackettLuce</a></span>(R)
<span class="kw">coef</span>(mod2)</code></pre></div>
<pre><code>##          A          B          C          D 
##  0.0000000  0.5184184  0.1354707 -1.1537564</code></pre>
<p>This is because there are only 5 rankings, so there is not much information in the data. In more realistic examples, the default prior will have a weak shrinkage effect, shrinking the item parameters towards <span class="math inline">\(1/N\)</span>, where <span class="math inline">\(N\)</span> is the number of items.</p>
<p>For a practical example, we consider the NASCAR data from <span class="citation">Hunter (<a href="#ref-Hunter2004">2004</a>)</span>. This collects the results of the 36 races in the 2002 NASCAR season in the United States. Each race involves 43 drivers out of a total of 87 drivers. The <code>d_nascar</code> data provided by <strong>PlackettLuce</strong> records the results as an ordering of the drivers in each race:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(nascar)
nascar[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">45</span>]</code></pre></div>
<pre><code>##      rank1 rank2 rank3 rank4 rank5 rank6 rank7 rank8 rank9 rank10 rank11
## [1,]    83    18    20    48    53    51    67    72    32     42      2
## [2,]    52    72     4    82    60    31    32    66     3     44      2
##      rank12 rank13 rank14 rank15 rank16 rank17 rank18 rank19 rank20 rank21
## [1,]     31     62     13     37      6     60     66     33     77     56
## [2,]     48     83     67     41     77     33     61     45     38     51
##      rank22 rank23 rank24 rank25 rank26 rank27 rank28 rank29 rank30 rank31
## [1,]     63     55     70     14     43     71     35     12     44     79
## [2,]     14     42     62     35     12     25     37     34      6     18
##      rank32 rank33 rank34 rank35 rank36 rank37 rank38 rank39 rank40 rank41
## [1,]      3     52      4      9     45     41     61     34     39     49
## [2,]     79     39     59     43     55     49     56      9     53      7
##      rank42 rank43 rank44 rank45
## [1,]     15     82      0      0
## [2,]     13     71      0      0</code></pre>
<p>For example, in the first race, driver 83 came first, followed by driver 18 and so on. Ranks 43 to 87 are zero for all races. We can convert these orderings to rankings using <code>as.rankings</code> with <code>input = "ordering"</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rankings.html">as.rankings</a></span>(nascar, <span class="dt">input =</span> <span class="st">"ordering"</span>)
R[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,]</code></pre></div>
<pre><code>## [1] "83 &gt; 18 &gt; 20 &gt; 48 &gt; 53 &gt; 51 &gt; 67 &gt; 7 ..."
## [2] "52 &gt; 72 &gt; 4 &gt; 82 &gt; 60 &gt; 31 &gt; 32 &gt; 66 ..."</code></pre>
<p>The names corresponding to the driver IDs are available as an attribute of <code>nascar</code>; since the columns of <code>R</code> now correspond to the drivers, we can use these as the column names:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colnames</span>(R) &lt;-<span class="st"> </span><span class="kw">attr</span>(nascar, <span class="st">"drivers"</span>)
R[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, as.rankings =<span class="st"> </span><span class="ot">FALSE</span>]</code></pre></div>
<pre><code>##      Austin Cameron Bill Elliott Bobby Hamilton
## [1,]              0           11             32
## [2,]              0           11              9
## [3,]              0            8             43</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]</code></pre></div>
<pre><code>## [1] "Ward Burton &gt; Elliott Sadler &gt; Geoff ..."
## [2] "Matt Kenseth &gt; Sterling Marlin &gt; Bob ..."
## [3] "Sterling Marlin &gt; Jeremy Mayfield &gt;  ..."</code></pre>
<p>Maximum likelihood estimation cannot be used in this example, because four drivers placed last in each race they entered. So <span class="citation">Hunter (<a href="#ref-Hunter2004">2004</a>)</span> dropped these four drivers to fit the Plackett-Luce model, which we can reproduce as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">keep &lt;-<span class="st"> </span><span class="kw">seq_len</span>(<span class="dv">83</span>)
R2 &lt;-<span class="st"> </span>R[, keep]
mod &lt;-<span class="st"> </span><span class="kw"><a href="../reference/PlackettLuce.html">PlackettLuce</a></span>(R2, <span class="dt">npseudo =</span> <span class="dv">0</span>)</code></pre></div>
<p>In order to demonstrate the correspondene with the results from <span class="citation">Hunter (<a href="#ref-Hunter2004">2004</a>)</span>, we order the item parameters by the deriver’s average rank:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">avRank &lt;-<span class="st"> </span><span class="kw">apply</span>(R, <span class="dv">2</span>, <span class="cf">function</span>(x) <span class="kw">mean</span>(x[x <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>]))
coefs &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">coef</span>(mod)[<span class="kw">order</span>(avRank[keep])], <span class="dv">2</span>)
<span class="kw">head</span>(coefs, <span class="dv">3</span>)</code></pre></div>
<pre><code>##     PJ Jones Scott Pruett  Mark Martin 
##         4.15         3.62         2.08</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tail</span>(coefs, <span class="dv">3</span>)</code></pre></div>
<pre><code>##  Dave Marcis Dick Trickle    Joe Varde 
##         0.03        -0.31        -0.15</code></pre>
<p>Now we fit the Plackett-Luce model to the full data, using the default pseudo-rankings method. In this case the default iterative scaling method does not perform very well, so we switch to the L-BFGS algorithm:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/PlackettLuce.html">PlackettLuce</a></span>(R, <span class="dt">method =</span> <span class="st">"L-BFGS"</span>)</code></pre></div>
<p>For items that were in the previous model, we see that the log-worth parameters generally shrink towards zero:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">coefs2 &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">coef</span>(mod2), <span class="dv">2</span>)
coefs2[<span class="kw">names</span>(coefs)[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>]]</code></pre></div>
<pre><code>##     PJ Jones Scott Pruett  Mark Martin 
##         3.20         2.77         1.91</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">coefs2[<span class="kw">names</span>(coefs)[<span class="dv">81</span><span class="op">:</span><span class="dv">83</span>]]</code></pre></div>
<pre><code>##  Dave Marcis Dick Trickle    Joe Varde 
##         0.02        -0.38        -0.12</code></pre>
<p>The new items have relative large negative log worth</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">coefs2[<span class="dv">84</span><span class="op">:</span><span class="dv">87</span>]</code></pre></div>
<pre><code>## Andy Hillenburg  Gary Bradberry  Jason Hedlesky   Randy Renfrow 
##           -2.17           -1.74           -1.59           -1.77</code></pre>
<p>Nonetheless, the estimates are finite and have finite standard errors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(<span class="kw">summary</span>(mod2))[<span class="dv">84</span><span class="op">:</span><span class="dv">87</span>,]</code></pre></div>
<pre><code>##                  Estimate Std. Error    z value  Pr(&gt;|z|)
## Andy Hillenburg -2.171071   1.812990 -1.1975088 0.2311083
## Gary Bradberry  -1.744721   1.855337 -0.9403792 0.3470231
## Jason Hedlesky  -1.590755   1.881695 -0.8453841 0.3978964
## Randy Renfrow   -1.768608   1.904853 -0.9284746 0.3531614</code></pre>
<p>Note that the reference here is simply the driver that comes first alphabetically: A. Cameron. We can plot the quasi-variances for a better comparison:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">qv &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/qvcalc/topics/qvcalc">qvcalc</a></span>(mod2)
qv<span class="op">$</span>qvframe &lt;-<span class="st"> </span>qv<span class="op">$</span>qvframe[<span class="kw">order</span>(<span class="kw">coef</span>(mod2)),]
<span class="kw">plot</span>(qv, <span class="dt">xlab =</span> <span class="ot">NULL</span>, <span class="dt">ylab =</span> <span class="st">"Ability (log)"</span>, <span class="dt">main =</span> <span class="ot">NULL</span>, <span class="dt">xaxt=</span><span class="st">"n"</span>)
<span class="kw">axis</span>(<span class="dv">1</span>, <span class="dt">at =</span> <span class="kw">seq_len</span>(<span class="dv">87</span>), <span class="dt">labels =</span> <span class="kw">rownames</span>(qv<span class="op">$</span>qvframe), <span class="dt">las =</span> <span class="dv">2</span>, <span class="dt">cex.axis =</span> <span class="fl">0.7</span>)</code></pre></div>
<div class="figure">
<img src="Overview_files/figure-html/nascar-qv-1.png" alt="Ability of drivers based on NASCAR 2002 season. Intervals based on quasi-standard errors." width="672"><p class="caption">
Ability of drivers based on NASCAR 2002 season. Intervals based on quasi-standard errors.
</p>
</div>
<p>Although the pseudo-rankings are only necessary to add when the network is incomplete, the default behaviour is always to use them (with a weight of 0.5) because the small shrinkage effect reduces the bias of the estimates.</p>
</div>
</div>
<div id="plackett-luce-trees" class="section level1">
<h1 class="hasAnchor">
<a href="#plackett-luce-trees" class="anchor"></a>Plackett-Luce Trees</h1>
<p>A Plackett-Luce model that assumes the same worth parameters across all rankings may sometimes be an over-simplification. For example, if rankings are made by different judges, the worth parameters may vary between judges with different characteristics. Model-based partitioning provides an automatic way to determine subgroups of the judges with significantly different sets of worth parameters, based on judge covariates. A Plackett-Luce tree is created via the following steps:</p>
<ol style="list-style-type: decimal">
<li>Fit a Plackett-Luce model to the full data.</li>
<li>Asses the stability of the worth parameters with respect to each available covariate.</li>
<li>If there is significant instability, split the full data by the covariate with the strongest instability and use the cut-point with the highest improvement in model fit.</li>
<li>Repeat steps 1-3 until there are no more significant instabilities, or a split produces a sub-group below a given size threshold.</li>
</ol>
<p>This is an extension of Bradley-Terry trees, implented in the R package <strong>psychotree</strong> and described in more detail by <span class="citation">Strobl, Wickelmaier, and Zeileis (<a href="#ref-Strobl2011">2011</a>)</span>.</p>
<p>To illustrate this approach, we consider data from a trial of different varieties of bean in Nicaragua, run by Bioversity International. Farmers were asked to grow three experimental varieties of bean in one of the growing seasons, Primera (May - August), Postrera (September - October) or Apante (November - January). At the end of the season, they were asked which variety they though was best and which variety they thought was worse, to give a ranking of the three varieties. In addition, they were asked to compare each trial variety to the standard local variety and say whether it was better or worse.</p>
<p>The data are provided as the dataset <code>beans</code> in Plackett-Luce. The data require some preparation to collate the rankings. First we consider the best and worst rankings. These give the variety the farmer though was best or worst, coded as A, B or C for the first, second or third variety assigned to the farmer respectively.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(beans)
<span class="kw">head</span>(beans[<span class="kw">c</span>(<span class="st">"best"</span>, <span class="st">"worst"</span>)], <span class="dv">2</span>)</code></pre></div>
<pre><code>## # A tibble: 2 x 2
##    best worst
##   &lt;chr&gt; &lt;chr&gt;
## 1     C     A
## 2     A     B</code></pre>
<p>We convert these to numeric values, allowing us to impute the middle-ranked variety (a strict ranking is assumed here, so the sum of each row should be 6)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beans &lt;-<span class="st"> </span><span class="kw">within</span>(beans, {
    best &lt;-<span class="st"> </span><span class="kw">match</span>(best, <span class="kw">c</span>(<span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>)) 
    worst &lt;-<span class="st"> </span><span class="kw">match</span>(worst, <span class="kw">c</span>(<span class="st">"A"</span>, <span class="st">"B"</span>, <span class="st">"C"</span>))
    middle &lt;-<span class="st"> </span><span class="dv">6</span> <span class="op">-</span><span class="st"> </span>best <span class="op">-</span><span class="st"> </span>worst
})
<span class="kw">head</span>(beans[<span class="kw">c</span>(<span class="st">"best"</span>, <span class="st">"middle"</span>, <span class="st">"worst"</span>)], <span class="dv">2</span>)</code></pre></div>
<pre><code>## # A tibble: 2 x 3
##    best middle worst
##   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;
## 1     3      2     1
## 2     1      3     2</code></pre>
<p>This gives an ordering of the three varieties the farmer was given. The names of these varieties are stored in separate columns</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varieties &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(beans[<span class="kw">c</span>(<span class="st">"variety_a"</span>, <span class="st">"variety_b"</span>, <span class="st">"variety_c"</span>)])
<span class="kw">head</span>(varieties, <span class="dv">2</span>)</code></pre></div>
<pre><code>##      variety_a        variety_b     variety_c     
## [1,] "INTA Rojo"      "PM2 Don Rey" "INTA Ferroso"
## [2,] "INTA Matagalpa" "INTA Rojo"   "ALS 0532-6"</code></pre>
<p>So we can convert the variety IDs to the variety names</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(beans)
beans &lt;-<span class="st"> </span><span class="kw">within</span>(beans, {
    best &lt;-<span class="st"> </span>varieties[<span class="kw">cbind</span>(<span class="kw">seq_len</span>(n), best)]
    worst &lt;-<span class="st"> </span>varieties[<span class="kw">cbind</span>(<span class="kw">seq_len</span>(n), worst)]
    middle &lt;-<span class="st"> </span>varieties[<span class="kw">cbind</span>(<span class="kw">seq_len</span>(n), middle)]
})
<span class="kw">head</span>(beans[<span class="kw">c</span>(<span class="st">"best"</span>, <span class="st">"middle"</span>, <span class="st">"worst"</span>)], <span class="dv">2</span>)</code></pre></div>
<pre><code>## # A tibble: 2 x 3
##             best      middle     worst
##            &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;
## 1   INTA Ferroso PM2 Don Rey INTA Rojo
## 2 INTA Matagalpa  ALS 0532-6 INTA Rojo</code></pre>
<p>Next we convert these orderings to sub-rankings of the full set of varieties, including the local variety as an additional item, so that we can add the paired comparisons shortly:</p>
<pre><code>```r
lab &lt;- c("Local", sort(unique(as.vector(varieties))))
R &lt;- as.rankings(beans[c("best", "middle", "worst")], 
             input = "ordering", labels = lab)
```</code></pre>
<p>The comparisons with the local variety are stored in another set of columns</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(beans[<span class="kw">c</span>(<span class="st">"var_a"</span>, <span class="st">"var_b"</span>, <span class="st">"var_c"</span>)], <span class="dv">2</span>)</code></pre></div>
<pre><code>## # A tibble: 2 x 3
##    var_a var_b  var_c
##    &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;
## 1  Worse Worse Better
## 2 Better Worse Better</code></pre>
<p>The following converts each of these columns to a matrix of ordered pairs:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">paired &lt;-<span class="st"> </span><span class="kw">list</span>()
<span class="cf">for</span> (id <span class="cf">in</span> <span class="kw">c</span>(<span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>)){
    ordering &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="st">"Local"</span>, <span class="dt">nrow =</span> n, <span class="dt">ncol =</span> <span class="dv">2</span>)
    worse &lt;-<span class="st"> </span>beans[[<span class="kw">paste0</span>(<span class="st">"var_"</span>, id)]] <span class="op">==</span><span class="st"> "Worse"</span>
    ## name of winner
    ordering[<span class="op">!</span>worse, <span class="dv">1</span>] &lt;-<span class="st"> </span>beans[[<span class="kw">paste0</span>(<span class="st">"variety_"</span>, id)]][<span class="op">!</span>worse]
    ## name of loser
    ordering[worse, <span class="dv">2</span>] &lt;-<span class="st"> </span>beans[[<span class="kw">paste0</span>(<span class="st">"variety_"</span>, id)]][worse]
    paired[[id]] &lt;-<span class="st"> </span>ordering
}
<span class="kw">head</span>(paired[[id]])</code></pre></div>
<pre><code>##      [,1]           [,2]         
## [1,] "INTA Ferroso" "Local"      
## [2,] "ALS 0532-6"   "Local"      
## [3,] "INTA Precoz"  "Local"      
## [4,] "Local"        "INTA Sequia"
## [5,] "BRT 103-182"  "Local"      
## [6,] "INTA Sequia"  "Local"</code></pre>
<p>Again we convert these orderings to sub-rankings of the full set of varieties and combine them with the rankings of order three:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">paired &lt;-<span class="st"> </span><span class="kw">lapply</span>(paired, as.rankings, <span class="dt">input =</span> <span class="st">"ordering"</span>, <span class="dt">labels =</span> lab)
R &lt;-<span class="st"> </span><span class="kw">rbind</span>(R, paired[[<span class="st">"a"</span>]], paired[[<span class="st">"b"</span>]], paired[[<span class="st">"c"</span>]])</code></pre></div>
<p>In order to fit a Plackett-Luce tree, we need to create a  object, that defines how the rankings map to the covariate values. In this case we wish to group by each record in the original data set, so we create a  object as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">G &lt;-<span class="st"> </span><span class="kw"><a href="../reference/grouped_rankings.html">grouped_rankings</a></span>(R, <span class="kw">rep</span>(<span class="kw">seq_len</span>(n), <span class="dv">4</span>))
<span class="kw">format</span>(<span class="kw">head</span>(G, <span class="dv">2</span>), <span class="dt">width =</span> <span class="dv">50</span>)</code></pre></div>
<pre><code>##                                                                      1 
##       "INTA Ferroso &gt; PM2 Don Rey &gt; INTA Rojo, Local &gt; INTA Rojo, ..." 
##                                                                      2 
## "INTA Matagalpa &gt; ALS 0532-6 &gt; INTA Rojo, INTA Matagalpa &gt; Local, ..."</code></pre>
<p>For each record in the original data, we have three covariates:  the season-year the beans were planted,  the year of planting, and  the maximum 5-day rainfall. The covariates will be used to fit a Plackett-Luce tree</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beans<span class="op">$</span>season &lt;-<span class="st"> </span><span class="kw">factor</span>(beans<span class="op">$</span>season, 
                       <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">"Ap - 15"</span>, <span class="st">"Ap - 16"</span>, <span class="st">"Ap - 17"</span>, <span class="st">"Po - 15"</span>,
                                  <span class="st">"Po - 16"</span>, <span class="st">"Pr - 16"</span>))
beans<span class="op">$</span>year &lt;-<span class="st"> </span><span class="kw">factor</span>(beans<span class="op">$</span>year)
tree &lt;-<span class="st"> </span><span class="kw"><a href="../reference/pltree.html">pltree</a></span>(G <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> beans[<span class="kw">c</span>(<span class="st">"season"</span>, <span class="st">"year"</span>, <span class="st">"rx5day"</span>)], <span class="dt">minsize =</span> <span class="dv">5</span>)
tree</code></pre></div>
<pre><code>## Plackett-Luce tree
## 
## Model formula:
## G ~ .
## 
## Fitted party:
## [1] root
## |   [2] season in Ap - 15, Ap - 17, Po - 16: n = 474
## |                 Local      ALS 0532-6     BRT 103-182 INTA Centro Sur 
## |           0.000000000    -0.651754640    -0.101890868    -0.092640118 
## |          INTA Ferroso  INTA Matagalpa     INTA Precoz       INTA Rojo 
## |          -0.258335730    -0.389046571    -0.429851602    -0.415413530 
## |           INTA Sequia     PM2 Don Rey      SJC 730-79 
## |          -0.008418586    -0.496615240    -0.509553228 
## |   [3] season in Ap - 16, Po - 15, Pr - 16: n = 368
## |                 Local      ALS 0532-6     BRT 103-182 INTA Centro Sur 
## |            0.00000000     -0.27799346     -0.59270341     -0.42433481 
## |          INTA Ferroso  INTA Matagalpa     INTA Precoz       INTA Rojo 
## |           -0.79633335     -0.37595043     -0.73396858     -0.28904726 
## |           INTA Sequia     PM2 Don Rey      SJC 730-79 
## |            0.01250816     -0.53362475     -0.50035757 
## 
## Number of inner nodes:    1
## Number of terminal nodes: 2
## Number of parameters per node: 11
## Objective function (negative log-likelihood): 3176.073</code></pre>
<p>In this case there are two nodes defined by the seasons.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(tree)</code></pre></div>
<p><img src="Overview_files/figure-html/unnamed-chunk-34-1.png" width="672"></p>
</div>
<div id="appendix" class="section level1">
<h1 class="hasAnchor">
<a href="#appendix" class="anchor"></a>Appendix</h1>
<p>For the package comparison in Table @ref(tab:timings-kable), the model was fitted to aggregated rankings where possible (PlackettLuce, hyper2, pmr). Arguments were set to obtain the maximum likelihood estimate, using the default iterative scaling algorithm for PlackettLuce. The functions were run with their default convergence criteria; the number of iterations for StatRank was set so that the log-likehood on exit was equal to the log-likelihood returned by the other functions with relative tolerance 1e-6.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PlackettLuce)
<span class="co"># read in example data sets</span>
preflib &lt;-<span class="st"> "http://www.preflib.org/data/election/"</span>
netflix &lt;-<span class="st"> </span><span class="kw"><a href="../reference/read.soc.html">read.soc</a></span>(<span class="kw">file.path</span>(preflib, <span class="st">"netflix/ED-00004-00000101.soc"</span>))
tshirt &lt;-<span class="st"> </span><span class="kw"><a href="../reference/read.soc.html">read.soc</a></span>(<span class="kw">file.path</span>(preflib, <span class="st">"shirt/ED-00012-00000001.soc"</span>))
sushi &lt;-<span class="st"> </span><span class="kw"><a href="../reference/read.soc.html">read.soc</a></span>(<span class="kw">file.path</span>(preflib, <span class="st">"sushi/ED-00014-00000001.soc"</span>))

<span class="co"># wrappers for each method</span>
pl &lt;-<span class="st"> </span><span class="cf">function</span>(dat, ...){
    <span class="co"># convert ordered items to ranking</span>
    R &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rankings.html">as.rankings</a></span>(dat[,<span class="op">-</span><span class="dv">1</span>], <span class="st">"ordering"</span>)
    <span class="co"># fit without adding pseudo-rankings, weight rankings by count</span>
    <span class="kw"><a href="../reference/PlackettLuce.html">PlackettLuce</a></span>(R, <span class="dt">npseudo =</span> <span class="dv">0</span>, <span class="dt">weights =</span> dat<span class="op">$</span>n)
}
hyper2 &lt;-<span class="st"> </span><span class="cf">function</span>(dat, ...){
    <span class="kw">requireNamespace</span>(<span class="st">"hyper2"</span>)
    <span class="co"># create likelihood object based on ordered items and counts</span>
    H &lt;-<span class="st"> </span>hyper2<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/hyper2/topics/hyper2">hyper2</a></span>(<span class="dt">pnames =</span> <span class="kw">paste0</span>(<span class="st">"p"</span>, <span class="kw">seq_len</span>(<span class="kw">ncol</span>(dat) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)))
    <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(<span class="kw">nrow</span>(dat))){
        x &lt;-<span class="st">  </span>dat[i, <span class="op">-</span><span class="dv">1</span>][dat[i, <span class="op">-</span><span class="dv">1</span>] <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>]
        H &lt;-<span class="st"> </span>H <span class="op">+</span><span class="st"> </span>hyper2<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/hyper2/topics/ggol">order_likelihood</a></span>(x, <span class="dt">times =</span> dat[i, <span class="dv">1</span>])
    }
    <span class="co"># find parameters to maximise likelihood</span>
    p &lt;-<span class="st"> </span>hyper2<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/hyper2/topics/maxp">maxp</a></span>(H)
    <span class="kw">structure</span>(p, <span class="dt">loglik =</span> hyper2<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/hyper2/topics/lhyper2">lhyper2</a></span>(H, p[<span class="op">-</span><span class="kw">length</span>(p)]))
}
plmix &lt;-<span class="st"> </span><span class="cf">function</span>(dat, ...){
    <span class="kw">requireNamespace</span>(<span class="st">"PLMIX"</span>)
    <span class="co"># disaggregate data (no functionality for weights or counts)</span>
    r &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">seq_len</span>(<span class="kw">nrow</span>(dat)), dat<span class="op">$</span>n)
    <span class="co"># maximum a posterioi estimate, with non-informative prior, </span>
    <span class="co"># K items in each ranking, single component distribution</span>
    <span class="co"># default starting values do not always work</span>
    K &lt;-<span class="st"> </span><span class="kw">ncol</span>(dat)
    PLMIX<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/PLMIX/topics/mapPLMIX">mapPLMIX</a></span>(<span class="kw">as.matrix</span>(dat[r, <span class="op">-</span><span class="dv">1</span>]), <span class="dt">K =</span> K, <span class="dt">G =</span> <span class="dv">1</span>, 
                    <span class="dt">init =</span> <span class="kw">list</span>(<span class="dt">p =</span> <span class="kw">rep.int</span>(<span class="dv">1</span><span class="op">/</span>K, K)), <span class="dt">plot_objective =</span> <span class="ot">FALSE</span>)
}
pmr &lt;-<span class="st"> </span><span class="cf">function</span>(dat, ...){
    <span class="kw">requireNamespace</span>(<span class="st">"pmr"</span>)
    <span class="co"># convert ordered items to ranking</span>
    R &lt;-<span class="st"> </span><span class="kw"><a href="../reference/rankings.html">as.rankings</a></span>(dat[,<span class="op">-</span><span class="dv">1</span>], <span class="st">"ordering"</span>)
    <span class="co"># create data frame with counts as required by pl</span>
    X &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">unclass</span>(R))
    X<span class="op">$</span>n &lt;-<span class="st"> </span>dat<span class="op">$</span>n
    <span class="kw">capture.output</span>(res &lt;-<span class="st"> </span>pmr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/pmr/topics/pl">pl</a></span>(X))
    res
}
statrank &lt;-<span class="st"> </span><span class="cf">function</span>(dat, iter){
    <span class="kw">requireNamespace</span>(<span class="st">"StatRank"</span>)
    <span class="co"># disaggregate data (no functionality for weights or counts)</span>
    r &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="kw">seq_len</span>(<span class="kw">nrow</span>(dat)), dat<span class="op">$</span>n)
    <span class="kw">capture.output</span>(res &lt;-<span class="st"> </span>StatRank<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/StatRank/topics/Estimation.PL.MLE">Estimation.PL.MLE</a></span>(<span class="kw">as.matrix</span>(dat[r, <span class="op">-</span><span class="dv">1</span>]), 
                                                      <span class="dt">iter =</span> iter))
    res
}
timings &lt;-<span class="st"> </span><span class="cf">function</span>(dat, <span class="dt">iter =</span> <span class="ot">NULL</span>,
                    <span class="dt">fun =</span> <span class="kw">c</span>(<span class="st">"pl"</span>, <span class="st">"hyper2"</span>, <span class="st">"plmix"</span>, <span class="st">"pmr"</span>, <span class="st">"statrank"</span>)){
    res &lt;-<span class="st"> </span><span class="kw">list</span>()
    <span class="cf">for</span> (nm <span class="cf">in</span> <span class="kw">c</span>(<span class="st">"pl"</span>, <span class="st">"hyper2"</span>, <span class="st">"plmix"</span>, <span class="st">"pmr"</span>, <span class="st">"statrank"</span>)){
        <span class="cf">if</span> (nm <span class="op">%in%</span><span class="st"> </span>fun){
            res[[nm]] &lt;-<span class="st"> </span><span class="kw">try</span>(
                <span class="kw">system.time</span>(<span class="kw">do.call</span>(nm, <span class="kw">list</span>(dat, iter)))[[<span class="st">"elapsed"</span>]],
                <span class="dt">silent =</span> <span class="ot">TRUE</span>)
        } <span class="cf">else</span> res[[nm]] &lt;-<span class="st"> </span><span class="ot">NA</span>
    }
    res
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set iter for statrank so that log-likelihood pass `all.equal` with tolerance 1e-6</span>
netflix_timings &lt;-<span class="st"> </span><span class="kw">timings</span>(netflix, <span class="dv">6</span>)
tshirt_timings &lt;-<span class="st"> </span><span class="kw">timings</span>(tshirt, <span class="dv">341</span>)
sushi_timings &lt;-<span class="st"> </span><span class="kw">timings</span>(sushi, <span class="dv">5</span>)</code></pre></div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-Davidson1970">
<p>Davidson, Roger R. 1970. “On extending the bradley-terry model to accommodate ties in paired comparison experiments.” <em>Journal of the American Statistical Association</em> 65 (329): 317–28. doi:<a href="https://doi.org/10.1080/01621459.1970.10481082">10.1080/01621459.1970.10481082</a>.</p>
</div>
<div id="ref-Hunter2004">
<p>Hunter, David R. 2004. “MM algorithms for generalized Bradley-Terry models.” <em>Annals of Statistics</em> 32 (1): 384–406. doi:<a href="https://doi.org/10.1214/aos/1079120141">10.1214/aos/1079120141</a>.</p>
</div>
<div id="ref-Luce1959">
<p>Luce, R. 1959. <em>Individual Choice Behavior: A Theoretical Analysis</em>. doi:<a href="https://doi.org/10.2307/2282347">10.2307/2282347</a>.</p>
</div>
<div id="ref-Luce1977">
<p>Luce, R. Duncan. 1977. “The choice axiom after twenty years.” <em>Journal of Mathematical Psychology</em> 15 (3): 215–33. doi:<a href="https://doi.org/10.1016/0022-2496(77)90032-3">10.1016/0022-2496(77)90032-3</a>.</p>
</div>
<div id="ref-Mattei2013">
<p>Mattei, Nicholas, and Toby Walsh. 2013. “PrefLib: A Library of Preference Data.” In <em>Proceedings of the 3rd International Conference on Algorithmic Decision Theory (Adt 2013)</em>. Lecture Notes in Artificial Intelligence. Springer. <a href="http://preflib.org" class="uri">http://preflib.org</a>.</p>
</div>
<div id="ref-Plackett1975">
<p>Plackett, R. L. 1975. “The Analysis of Permutations.” <em>Appl. Statist</em> 24 (2): 193–202. doi:<a href="https://doi.org/10.2307/2346567">10.2307/2346567</a>.</p>
</div>
<div id="ref-Strobl2011">
<p>Strobl, C., F. Wickelmaier, and A. Zeileis. 2011. “Accounting for Individual Differences in Bradley-Terry Models by Means of Recursive Partitioning.” <em>Journal of Educational and Behavioral Statistics</em> 36 (2). SAGE PublicationsSage CA: Los Angeles, CA: 135—–153. doi:<a href="https://doi.org/10.3102/1076998609359791">10.3102/1076998609359791</a>.</p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#introduction">Introduction</a><ul class="nav nav-pills nav-stacked">
<li><a href="#comparison-with-other-packages">Comparison with other packages</a></li>
      </ul>
</li>
      <li>
<a href="#methods">Methods</a><ul class="nav nav-pills nav-stacked">
<li><a href="#extended-plackett-luce-model">Extended Plackett-Luce model</a></li>
      <li><a href="#inference">Inference</a></li>
      <li><a href="#disconnected-networks">Disconnected networks</a></li>
      </ul>
</li>
      <li><a href="#plackett-luce-trees">Plackett-Luce Trees</a></li>
      <li><a href="#appendix">Appendix</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Heather Turner, Ioannis Kosmidis, David Firth.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
